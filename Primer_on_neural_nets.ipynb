{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwXjngU8JFAimOJaIwTx//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/unet-workshop/blob/main/Primer_on_neural_nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QFGlqz6AQQV"
      },
      "source": [
        "# Introducción rápida a las redes neuronales ⚡️\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro** ([Future Lab](https://futurelab.mx/), 2023 _–actualizado_). <br>\n",
        "> Contacto: ig - [@rodo_ferro](https://www.instagram.com/rodo_ferro/) & tw - [@rodo_ferro](https://twitter.com/rodo_ferro)\n",
        "\n",
        "En este cuaderno podrás encontrar un código base que implementa una neurona artifical, incluyendo el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_BXRzLrBEdd"
      },
      "source": [
        "------\n",
        "\n",
        "## Una neurona artificial\n",
        "\n",
        "Comenzaremos analizando la implementación de una red neuronal artificial utilizando sólo Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p7Tqyz-zfti"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class ArtificialNeuron():\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        n : int\n",
        "            Input size.\n",
        "        \"\"\"\n",
        "        \n",
        "        np.random.seed(123)\n",
        "        self.synaptic_weights = 2 * np.random.random((n, 1)) - 1 # TODO. Use np.random.random((n, 1)) to gen values in (-1, 1)\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        \"\"\"Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to sigmoid function.\n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO: Return result of sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to evaluated sigmoid function.\"\"\"\n",
        "\n",
        "        # TODO: Return the derivate of sigmoid function x * (1 - x)\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_output, iterations):\n",
        "        \"\"\"Training function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        training_inputs : list\n",
        "            List of features for training.\n",
        "        training_outputs : list\n",
        "            List of labels for training.\n",
        "        iterations : int\n",
        "            Number of iterations for training.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        history : list\n",
        "            A list containing the training history.\n",
        "        \"\"\"\n",
        "\n",
        "        history = []\n",
        "        \n",
        "        for iteration in range(iterations):\n",
        "            output = self.predict(training_inputs)\n",
        "            \n",
        "            # MSE\n",
        "            output_col = training_output.reshape((len(training_inputs), 1))\n",
        "            error = np.mean((output_col - output)**2)\n",
        "            \n",
        "            adjustment = np.dot(training_inputs.T, error *\n",
        "                                self.__sigmoid_derivative(output))\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "            history.append(np.linalg.norm(error))\n",
        "        \n",
        "        return history\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Prediction function. Applies input function to inputs tensor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of inputs to apply sigmoid function.\n",
        "        \"\"\"\n",
        "        # TODO: Apply self.__sigmoid to np.dot of (inputs, self.synaptic_weights)\n",
        "        return self.__sigmoid(np.dot(inputs, self.synaptic_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos los datos para la neurona artificial."
      ],
      "metadata": {
        "id": "JyZtw3E34pzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training samples\n",
        "input_values = [(0, 1), (1, 0), (0, 0)]   # TODO. Define the input values as a list of tuples\n",
        "output_values = [1, 1, 0]  # TODO. Define the desired outputs\n",
        "\n",
        "training_inputs = np.array(input_values)\n",
        "training_output = np.array(output_values).T.reshape((3, 1))"
      ],
      "metadata": {
        "id": "GCk0WfQa4ORd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciamos la neurona."
      ],
      "metadata": {
        "id": "CvN_Ifyy4sCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the neuron\n",
        "neuron = ArtificialNeuron(2)\n",
        "print(\"Initial random weights:\")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "PTMHu1SN4RJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la neurona durante algunas épocas."
      ],
      "metadata": {
        "id": "YS0r-kmC4tfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO.\n",
        "# Modify the number of epochs to see how it performs.\n",
        "epochs = 10\n",
        "\n",
        "# We train the neuron a number of epochs:\n",
        "history = neuron.train(training_inputs, training_output, epochs)\n",
        "print(\"New synaptic weights after training: \")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "KzHemMfG4YEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos la historia de entrenamiento."
      ],
      "metadata": {
        "id": "B4RU1WPd4xBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "x = np.arange(len(history))\n",
        "y = history\n",
        "\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "80d_Fzv84ehn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ponemos a prueba con una predicción."
      ],
      "metadata": {
        "id": "RFi8_fkW4z_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We predict to verify the performance\n",
        "one_one = np.array((1, 1))\n",
        "print(\"Prediction for (1, 1): \")\n",
        "neuron.predict(one_one)"
      ],
      "metadata": {
        "id": "RY7xrPsR4g-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8IkF4N2DJV6"
      },
      "source": [
        "Esta neurona aunque ha sido implementada desde cero, puede ser implementada de manera sencilla utilizando TensorFlow. Veamos cómo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "## Introducción a TensorFlow\n",
        "\n",
        "A continuación recrearemos la misma neurona utilizando TensorFlow.\n",
        "\n",
        "Para esto, es necesario importar específicamente los tipos de capas y modelos a utilizar.\n",
        "\n",
        "Analicemos un poco los detalles:"
      ],
      "metadata": {
        "id": "UtMIYSYCsyBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(2,)))\n",
        "\n",
        "model.compile(loss='mse', optimizer='sgd')"
      ],
      "metadata": {
        "id": "d_sR757ms5bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar el modelo, también utilizaremos el método fit."
      ],
      "metadata": {
        "id": "Wx8Ck_UQuW5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(training_inputs, training_output, epochs=epochs, batch_size=1)"
      ],
      "metadata": {
        "id": "XNx8ciTBtOhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y de igual manera, podemos acceder al historial de entrenamiento."
      ],
      "metadata": {
        "id": "VO_N2CKluaLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "47Ku2lh5tcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "x = np.arange(len(history.history['loss']))\n",
        "y = history.history['loss']\n",
        "\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "mG_jRYHqtYQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, ¿esto cómo escala a trabajar con redes que utilizan más de una capa y más de una neurona? Veamos.\n",
        "\n",
        "Para resolver un problema más elaborado creando una red profunda, utilizaremos otros datos, los cuales cargaremos a continuación. \n",
        "\n",
        "Los datos de Fashion MNIST están disponibles directamente en la API de conjuntos de datos de `tf.keras`. Llamar a load_data en este objeto nos dará dos conjuntos con los valores de entrenamiento y prueba para los gráficos que contienen las prendas y sus etiquetas."
      ],
      "metadata": {
        "id": "p0-n3OCyuoQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "WEV21IJJvqEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo se ven estos valores? Despleguemos una imagen de entrenamiento y una etiqueta de entrenamiento para saber."
      ],
      "metadata": {
        "id": "dfvbC_UewVZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "# Set index of image to be seen\n",
        "img_index = 3000 # 6000 -1\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(training_images[img_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", training_labels[img_index])\n",
        "print(\"Matrix:\", training_images[img_index])"
      ],
      "metadata": {
        "id": "m8lf8r2IvvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notarás que todos los valores están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si transformamos los valores para tratar todos con valores entre 0 y 1."
      ],
      "metadata": {
        "id": "iNlmvxJ7wagU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "DA7Oh9Kov3we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "# Set index of image to be seen\n",
        "img_index = 3000 # 6000 -1\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(training_images[img_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", training_labels[img_index])\n",
        "print(\"Matrix:\", training_images[img_index])"
      ],
      "metadata": {
        "id": "gTlW07_0v65A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que cada imagen es sólo una matriz de 28x28 pixeles, sólo con 1 canal de color."
      ],
      "metadata": {
        "id": "zURylVeHwpiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images[0].shape"
      ],
      "metadata": {
        "id": "wnwJemqkwoDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploraremos una segunda forma de crear un modelo secuencial."
      ],
      "metadata": {
        "id": "P8xbNplEwk8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # TODO. Dense -> 256, ReLU\n",
        "    # TODO. Dense -> 10, Softmax\n",
        "])"
      ],
      "metadata": {
        "id": "YufcQNV1u8S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilaremos y entrenaremos el modelo.\n",
        "\n",
        "Notemos que se utilizan otros parámetros de compilación."
      ],
      "metadata": {
        "id": "RNzAEV61xGKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.compile(\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "EizBOSZBw0gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.fit(training_images, training_labels, epochs=3)"
      ],
      "metadata": {
        "id": "gV-K8llnw3FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo incluye funciones que nos permiten evaluar sus resultados, utilizand el conjunto de datos de prueba."
      ],
      "metadata": {
        "id": "Il7cjCcjw-_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "4nSOGLDfw-gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos explorar los resultados del modelo al inferir individualmente con una sola imagen."
      ],
      "metadata": {
        "id": "N3iW_rSsvgwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_index = random.randint(0, 10000 - 1)\n",
        "\n",
        "plt.imshow(test_images[test_index], cmap='viridis')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "input_image = np.reshape(test_images[test_index], (1, 784))\n",
        "prediction = mlp_model.predict(np.expand_dims(input_image, axis=-1))\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "ESBpRrVTxUrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA1wiuc01lQd"
      },
      "source": [
        "------\n",
        "\n",
        "## Convoluciones en imágenes\n",
        "\n",
        "Exploremos qué sucede cuando barremos un filtro (kernel) sobre una imagen utilizando una convolución.\n",
        "\n",
        "**Spoiler:** Intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kdal-XjznDC"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# We load a sample image\n",
        "img = datasets.ascent()\n",
        "\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una copia de la imagen."
      ],
      "metadata": {
        "id": "Mbmr-R6Yyv36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed = np.copy(img)\n",
        "size_x = img_transformed.shape[0]\n",
        "size_y = img_transformed.shape[1]"
      ],
      "metadata": {
        "id": "HNcuUIMjx_VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un filtro a utilizar."
      ],
      "metadata": {
        "id": "2nqmKQ94yxX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's experiment with different values\n",
        "\n",
        "filter = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
        "# filter = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "# filter = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "weight = 1 / 8"
      ],
      "metadata": {
        "id": "ckPpotCCyIKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos las operaciones."
      ],
      "metadata": {
        "id": "B_jvUdSOyy_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(1, size_x - 1):\n",
        "  for y in range(1, size_y - 1):\n",
        "      convolution = 0.0\n",
        "      convolution = convolution + (img[x - 1, y - 1] * filter[0][0])\n",
        "      convolution = convolution + (img[x, y - 1] * filter[0][1])\n",
        "      convolution = convolution + (img[x + 1, y - 1] * filter[0][2])\n",
        "      convolution = convolution + (img[x - 1, y] * filter[1][0])\n",
        "      convolution = convolution + (img[x, y] * filter[1][1])\n",
        "      convolution = convolution + (img[x + 1, y] * filter[1][2])\n",
        "      convolution = convolution + (img[x - 1, y + 1] * filter[2][0])\n",
        "      convolution = convolution + (img[x, y + 1] * filter[2][1])\n",
        "      convolution = convolution + (img[x + 1, y + 1] * filter[2][2])\n",
        "      convolution = convolution * weight\n",
        "      \n",
        "      if convolution < 0:\n",
        "        convolution = 0\n",
        "      if convolution > 255:\n",
        "        convolution = 255\n",
        "      \n",
        "      img_transformed[x, y] = convolution"
      ],
      "metadata": {
        "id": "4LQtpt51yKvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los resultados de convolución."
      ],
      "metadata": {
        "id": "9W8I0UdWy1hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X4k5e1TnyM9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "\n",
        "## Redes convolucionales\n",
        "\n",
        "**Spoiler:** Nuevamente, intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal.\n",
        "\n",
        "Para ello, crearemos un modelo de red neuronal convolucional profunda, que utilice, precisamente, convoluciones en sus capas.\n",
        "\n",
        "Nos basaremos en un modelo LeNet5 propuesto por un gran investigador, Yann LeCun:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg\" width=\"60%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "cCnKW5c0y9Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First conv layer + subsampling\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second conv layer + subsampling\n",
        "    # TODO. Conv2D -> 256, (3, 3), ReLU\n",
        "    # TODO. MaxPool\n",
        "\n",
        "    # Third layer (flatten)\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fourth layer (dense)\n",
        "    # TODO. Dense -> 128, ReLU\n",
        "\n",
        "    # Fifth layer (output)\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "stCt0xNzzk_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q85XFofVzskY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(training_images, training_labels, epochs=2)"
      ],
      "metadata": {
        "id": "ZwGZ6QBgz7Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "6Uxhd3HVz88g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_index = random.randint(0, 10000 - 1)\n",
        "\n",
        "plt.imshow(test_images[test_index], cmap='viridis')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "input_image = np.reshape(test_images[test_index], (1, 28, 28, 1))\n",
        "prediction = cnn_model.predict(input_image)\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "MXzIcx4Kz-b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsmVIiyTE51p"
      },
      "source": [
        "**¡Felicidades! Has implementado y entrenado exitosamente tu modelo para clasificar algunas imágenes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reto:** ¿Puedes mejorar aún más el modelo?\n",
        "\n",
        "Te recomiendo explorar lo siguiente:\n",
        "- Modifica el número de capas y parámetros de convolución por capa\n",
        "- Modifica el número de épocas de entrenamiento\n",
        "- Explora resultados con otros conjuntos de datos\n",
        "- ¿Exportar modelos entrenados? Ojo: https://www.tensorflow.org/guide/keras/save_and_serialize?hl=es-419"
      ],
      "metadata": {
        "id": "8U1tdrMYlDen"
      }
    }
  ]
}